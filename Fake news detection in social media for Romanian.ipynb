{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faced-comment",
   "metadata": {},
   "source": [
    "# Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "related-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilitaries\n",
    "from csv import reader\n",
    "import re\n",
    "import pandas as pd\n",
    "import zeep\n",
    "# Text manipulation\n",
    "\n",
    "# Data preparation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as stp\n",
    "import nltk.stem.snowball as snowball\n",
    "# Machine learning tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Machine learning classificators\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Machine learning model metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-tennessee",
   "metadata": {},
   "source": [
    "# Reading the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "answering-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "authentic-forty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>translation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>TVR</td>\n",
       "      <td>Rezultate parțiale BEC, după centralizarea a 9...</td>\n",
       "      <td>PSD a obținut la alegerile parlamentare  29,64...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>TVR</td>\n",
       "      <td>Marcel Ciolacu: Voi avea o discuție cu colegii...</td>\n",
       "      <td>Președintele PSD, Marcel Ciolacu, a declarat c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Ionut</td>\n",
       "      <td>Cel mai norocos oltean. A găsit o sarma cu pat...</td>\n",
       "      <td>Chiar dacă a găsit sarmaua cu patru foi, oltea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>TVR</td>\n",
       "      <td>Bugetul, dezbătut intens în comisiile de speci...</td>\n",
       "      <td>ACTUALIZARE Bugetul Casei Naţionale de Asigură...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Eftimie</td>\n",
       "      <td>Fum alb la negocieri. Ludovic Orban fumează ia...</td>\n",
       "      <td>„Doar un fum să mai trag”, a declarat liderul ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author                                              title  \\\n",
       "928      TVR  Rezultate parțiale BEC, după centralizarea a 9...   \n",
       "920      TVR  Marcel Ciolacu: Voi avea o discuție cu colegii...   \n",
       "430    Ionut  Cel mai norocos oltean. A găsit o sarma cu pat...   \n",
       "700      TVR  Bugetul, dezbătut intens în comisiile de speci...   \n",
       "342  Eftimie  Fum alb la negocieri. Ludovic Orban fumează ia...   \n",
       "\n",
       "                                           translation  label  \n",
       "928  PSD a obținut la alegerile parlamentare  29,64...      1  \n",
       "920  Președintele PSD, Marcel Ciolacu, a declarat c...      1  \n",
       "430  Chiar dacă a găsit sarmaua cu patru foi, oltea...      0  \n",
       "700  ACTUALIZARE Bugetul Casei Naţionale de Asigură...      1  \n",
       "342  „Doar un fum să mai trag”, a declarat liderul ...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-niger",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-implement",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "_Source: http://nlptools.info.uaic.ro/WebPosRo/_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twelve-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsdl = 'http://nlptools.info.uaic.ro/WebPosRo/PosTaggerRoWS?wsdl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "figured-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = zeep.Client(wsdl=wsdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-first",
   "metadata": {},
   "source": [
    "#### Transforming each article using the POS tagger,tokenizing and filtering the stopwords at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_articles_xml=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amber-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in df['translation']:\n",
    "     lemmatized_articles_xml.append(client.service.parseSentence_XML(article))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "recent-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving the articles to save execution time\n",
    "# for article in lemmatized_articles_xml:\n",
    "#     with open('lemmatized_articles','a+') as f:\n",
    "#         f.write(article)\n",
    "#         f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "earlier-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stp.words('romanian')\n",
    "lemmatized_articles_clean=[]\n",
    "for article in lemmatized_articles_xml:\n",
    "    article = article.split('\\n')\n",
    "    lemmas = []\n",
    "    for line in article:\n",
    "        found = re.search('.*LEMMA=\"([A-Za-zăâîșț1-9]*)\".*', line)\n",
    "        if found:\n",
    "            word = found.group(1)\n",
    "            if word not in stopwords:\n",
    "                lemmas.append(word)\n",
    "    lemmatized_articles_clean.append(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-customer",
   "metadata": {},
   "source": [
    "#### Adding the lemmatized articles to the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "vertical-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized_articles'] = lemmatized_articles_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "particular-edwards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>translation</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmatized_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>TVR</td>\n",
       "      <td>Cum își petrec politicienii Crăciunul</td>\n",
       "      <td>Masa trebuie să fie plină de bucate speciale î...</td>\n",
       "      <td>1</td>\n",
       "      <td>[masă, trebui, plin, bucată, special, Cristina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>Vasile</td>\n",
       "      <td>Testul COVID făcut de naționala de fotbal arat...</td>\n",
       "      <td>„COVID n-am găsit, dar până la urmă, mai conte...</td>\n",
       "      <td>0</td>\n",
       "      <td>[COVID, găsi, conta, adăuga, medic, testa, spo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>TVR</td>\n",
       "      <td>Diana Șoșoacă, fără sprijinul partidului AUR</td>\n",
       "      <td>DAN TANASĂ, deputat AUR: \"M-a deranjat acel ep...</td>\n",
       "      <td>1</td>\n",
       "      <td>[dan, tanasă, deputat, aur, deranja, episod, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Calin</td>\n",
       "      <td>Ce ghiolban! O specie de țânțar râgâie după ce...</td>\n",
       "      <td>”Nu sunt adeptul soluțiilor extreme, dar aceas...</td>\n",
       "      <td>0</td>\n",
       "      <td>[adept, soluție, extrem, specie, țânțar, trebu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>TVR</td>\n",
       "      <td>Orban: Nu s-a luat nicio decizie legată de spo...</td>\n",
       "      <td>El a adăugat că studenţii vor avea în continua...</td>\n",
       "      <td>1</td>\n",
       "      <td>[adăuga, student, vrea, gratuitate, călătorie,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author                                              title  \\\n",
       "838     TVR              Cum își petrec politicienii Crăciunul   \n",
       "542  Vasile  Testul COVID făcut de naționala de fotbal arat...   \n",
       "742     TVR       Diana Șoșoacă, fără sprijinul partidului AUR   \n",
       "141   Calin  Ce ghiolban! O specie de țânțar râgâie după ce...   \n",
       "751     TVR  Orban: Nu s-a luat nicio decizie legată de spo...   \n",
       "\n",
       "                                           translation  label  \\\n",
       "838  Masa trebuie să fie plină de bucate speciale î...      1   \n",
       "542  „COVID n-am găsit, dar până la urmă, mai conte...      0   \n",
       "742  DAN TANASĂ, deputat AUR: \"M-a deranjat acel ep...      1   \n",
       "141  ”Nu sunt adeptul soluțiilor extreme, dar aceas...      0   \n",
       "751  El a adăugat că studenţii vor avea în continua...      1   \n",
       "\n",
       "                                   lemmatized_articles  \n",
       "838  [masă, trebui, plin, bucată, special, Cristina...  \n",
       "542  [COVID, găsi, conta, adăuga, medic, testa, spo...  \n",
       "742  [dan, tanasă, deputat, aur, deranja, episod, d...  \n",
       "141  [adept, soluție, extrem, specie, țânțar, trebu...  \n",
       "751  [adăuga, student, vrea, gratuitate, călătorie,...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-settlement",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "surprising-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_articles = []\n",
    "stemmer = snowball.SnowballStemmer('romanian')\n",
    "\n",
    "for article in df['lemmatized_articles']:\n",
    "    stemmed_words =[]\n",
    "    for word in article:\n",
    "        stemmed_words.append(stemmer.stem(word))\n",
    "        # Appending the string form of the stemmed array because it will\n",
    "        # be needed in the next step\n",
    "    stemmed_articles.append(' '.join(stemmed_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-nirvana",
   "metadata": {},
   "source": [
    "#### Adding the stemmed articles to the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "emotional-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed_articles']=stemmed_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "twelve-thing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>translation</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmatized_articles</th>\n",
       "      <th>stemmed_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Calin</td>\n",
       "      <td>România a decis să nu se prezinte la meciul cu...</td>\n",
       "      <td>Vestea a fost primită cu optimism de jucătorii...</td>\n",
       "      <td>0</td>\n",
       "      <td>[veste, primit, optimism, jucător, lot, națion...</td>\n",
       "      <td>vest primit optimist jucat lot național grij v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Vasile</td>\n",
       "      <td>Validarea lui Ciucu ca primar, blocată în inst...</td>\n",
       "      <td>„Specialiştii noştri atrag atenţia că numele d...</td>\n",
       "      <td>0</td>\n",
       "      <td>[specialist, atrage, atenție, nume, domn, ciuc...</td>\n",
       "      <td>specialist atrag atenț num domn ciucu asemăn b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Calin</td>\n",
       "      <td>Nea Costel s-a consultat cu liderii de birt și...</td>\n",
       "      <td>„Am un singur mesaj pentru Orban: dă-te-n p… m...</td>\n",
       "      <td>0</td>\n",
       "      <td>[singur, mesaj, orban, puncte, transmite, nea,...</td>\n",
       "      <td>singur mesaj orban punct transmit nea costel ț...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Vasile</td>\n",
       "      <td>Viorica Dăncilă îl acuză pe Iohannis că a inve...</td>\n",
       "      <td>„Nu doar cuvinte ca giroscop sau funambulesc s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[cuvânt, giroscop, funambulesc, inventat, Ioha...</td>\n",
       "      <td>cuvânt giroscop funambul invent iohannis și ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Eftimie</td>\n",
       "      <td>Coca-Cola salvează industria ţiţeiului dublând...</td>\n",
       "      <td>Pe lângă cola, și alte băuturi din gamă vor be...</td>\n",
       "      <td>0</td>\n",
       "      <td>[cola, și, băutură, gamă, vrea, beneficia, pet...</td>\n",
       "      <td>col și băut gam vre benefic petrol gust putern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author                                              title  \\\n",
       "587    Calin  România a decis să nu se prezinte la meciul cu...   \n",
       "398   Vasile  Validarea lui Ciucu ca primar, blocată în inst...   \n",
       "345    Calin  Nea Costel s-a consultat cu liderii de birt și...   \n",
       "404   Vasile  Viorica Dăncilă îl acuză pe Iohannis că a inve...   \n",
       "169  Eftimie  Coca-Cola salvează industria ţiţeiului dublând...   \n",
       "\n",
       "                                           translation  label  \\\n",
       "587  Vestea a fost primită cu optimism de jucătorii...      0   \n",
       "398  „Specialiştii noştri atrag atenţia că numele d...      0   \n",
       "345  „Am un singur mesaj pentru Orban: dă-te-n p… m...      0   \n",
       "404  „Nu doar cuvinte ca giroscop sau funambulesc s...      0   \n",
       "169  Pe lângă cola, și alte băuturi din gamă vor be...      0   \n",
       "\n",
       "                                   lemmatized_articles  \\\n",
       "587  [veste, primit, optimism, jucător, lot, națion...   \n",
       "398  [specialist, atrage, atenție, nume, domn, ciuc...   \n",
       "345  [singur, mesaj, orban, puncte, transmite, nea,...   \n",
       "404  [cuvânt, giroscop, funambulesc, inventat, Ioha...   \n",
       "169  [cola, și, băutură, gamă, vrea, beneficia, pet...   \n",
       "\n",
       "                                      stemmed_articles  \n",
       "587  vest primit optimist jucat lot național grij v...  \n",
       "398  specialist atrag atenț num domn ciucu asemăn b...  \n",
       "345  singur mesaj orban punct transmit nea costel ț...  \n",
       "404  cuvânt giroscop funambul invent iohannis și ga...  \n",
       "169  col și băut gam vre benefic petrol gust putern...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-matter",
   "metadata": {},
   "source": [
    "# Preparation for the Machine Learning training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-shark",
   "metadata": {},
   "source": [
    "#### Extracting the article labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "freelance-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-palmer",
   "metadata": {},
   "source": [
    "#### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "assumed-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(df['stemmed_articles'], label, test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-white",
   "metadata": {},
   "source": [
    "# Trying different Machine Learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "tight-webcam",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'afirmaț însă greu cred întrucât om sin căut cas zon susțin așa sfârșit lum apartament groap guno glin simț miros pucioas și ansamblu rezidențial acolo cinc minut metrou'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-f885e3e194a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnb_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    766\u001b[0m               dtype='datetime64[ns]')\n\u001b[1;32m    767\u001b[0m         \"\"\"\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'afirmaț însă greu cred întrucât om sin căut cas zon susțin așa sfârșit lum apartament groap guno glin simț miros pucioas și ansamblu rezidențial acolo cinc minut metrou'"
     ]
    }
   ],
   "source": [
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
